{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab242341",
   "metadata": {},
   "source": [
    "# Tugas 1 - Sinyal Respirasi dan Post-Processing\n",
    "\n",
    "Berdasarkan apa yang telah kita coba mengenai metode pengambilan sinyal respirasi menggunakan mediapipe. Menggunakan video yang kalian ambil masing-masing pada tahap Pre-requisite modul ini. Lakukan proses pengambilan sinyal respirasi dan juga post-processingnya dalam menentukan laju pernafasan per menit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fdd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the stopwatch data\n",
    "stopwatch_df = pd.read_csv('stopwatch.csv')\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                                  max_num_faces=1,\n",
    "                                  min_detection_confidence=0.5,\n",
    "                                  min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to extract respiratory signal\n",
    "def extract_respiratory_signal(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Nose position tracking for respiratory signal\n",
    "    nose_y_positions = []\n",
    "    timestamps = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert to RGB for MediaPipe\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image\n",
    "        results = face_mesh.process(frame_rgb)\n",
    "        \n",
    "        current_time = frame_count / fps\n",
    "        timestamps.append(current_time)\n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            face_landmarks = results.multi_face_landmarks[0]\n",
    "            \n",
    "            # Extract nose position (using point 1)\n",
    "            nose_landmark = face_landmarks.landmark[1]\n",
    "            nose_y = nose_landmark.y\n",
    "            nose_y_positions.append(nose_y)\n",
    "        else:\n",
    "            # If no face is detected, use the last known position or a default\n",
    "            if nose_y_positions:\n",
    "                nose_y_positions.append(nose_y_positions[-1])\n",
    "            else:\n",
    "                nose_y_positions.append(0)\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Display progress\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return np.array(nose_y_positions), np.array(timestamps), fps\n",
    "\n",
    "# Process the video\n",
    "resp_signal, timestamps, fps = extract_respiratory_signal('dsp_ho3.mp4')\n",
    "\n",
    "# Post-processing\n",
    "def process_respiratory_signal(signal_data, timestamps, fps):\n",
    "    # Convert to inverted normalized signal\n",
    "    signal_inverted = -1 * (signal_data - np.mean(signal_data)) / np.std(signal_data)\n",
    "    \n",
    "    # Apply bandpass filter to isolate respiratory frequencies (0.1-0.5 Hz)\n",
    "    b, a = signal.butter(3, [0.1, 0.5], 'bandpass', fs=fps)\n",
    "    filtered_signal = signal.filtfilt(b, a, signal_inverted)\n",
    "    \n",
    "    # Find peaks for breath counting\n",
    "    peaks, _ = find_peaks(filtered_signal, height=0.1, distance=fps)\n",
    "    \n",
    "    # Calculate breaths per minute at different time points\n",
    "    breaths_per_minute = []\n",
    "    window_size = 30  # 30 seconds window\n",
    "    \n",
    "    for i in range(len(timestamps)):\n",
    "        if timestamps[i] < window_size:\n",
    "            continue\n",
    "        \n",
    "        # Count peaks in the last window_size seconds\n",
    "        start_time = timestamps[i] - window_size\n",
    "        window_start_idx = np.argmax(timestamps >= start_time)\n",
    "        \n",
    "        peaks_in_window = np.sum((timestamps[peaks] >= start_time) & \n",
    "                                 (timestamps[peaks] <= timestamps[i]))\n",
    "        \n",
    "        # Convert to breaths per minute\n",
    "        bpm = (peaks_in_window / window_size) * 60\n",
    "        breaths_per_minute.append((timestamps[i], bpm))\n",
    "    \n",
    "    return filtered_signal, peaks, np.array(breaths_per_minute)\n",
    "\n",
    "# Process the respiratory signal\n",
    "filtered_signal, resp_peaks, breaths_per_min = process_respiratory_signal(resp_signal, timestamps, fps)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot respiratory signal\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(timestamps, resp_signal)\n",
    "plt.title('Raw Respiratory Signal (Nose Y-Position)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Nose Y-Position')\n",
    "\n",
    "# Plot filtered signal with peaks\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(timestamps, filtered_signal)\n",
    "plt.plot(timestamps[resp_peaks], filtered_signal[resp_peaks], 'ro')\n",
    "plt.title('Filtered Respiratory Signal with Detected Breaths')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Plot breaths per minute over time\n",
    "plt.subplot(3, 1, 3)\n",
    "if len(breaths_per_min) > 0:\n",
    "    plt.plot(breaths_per_min[:, 0], breaths_per_min[:, 1])\n",
    "    plt.title('Respiratory Rate (Breaths per Minute)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Breaths per Minute')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare with stopwatch data\n",
    "if not stopwatch_df.empty:\n",
    "    print(\"Comparing with stopwatch data:\")\n",
    "    avg_bpm = np.mean(breaths_per_min[:, 1]) if len(breaths_per_min) > 0 else 0\n",
    "    print(f\"Average calculated respiratory rate: {avg_bpm:.2f} BPM\")\n",
    "    print(f\"Stopwatch data: {stopwatch_df.to_string(index=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63be2bd",
   "metadata": {},
   "source": [
    "# Tugas 2 - Metode Lucas-Kanade Optical Flow\n",
    "\n",
    "Kita menggunakan banyak metode dalam melakukan proses pengambilan sinyal pernafasan ini seperti apa itu Lucas-Kanade Optical Flow, tetapi kita tidak cukup detail dalam membahasnya kali ini. Anggap diri kamu sebagai periset independen, lakukan riset mandiri dan jelaskan konsep-konsep dan step yang kamu gunakan sampai kamu bisa mendapatkan laju pernafasan pada video kamu, dan jangan lupa untuk membandingkan hasil data dari video kamu dengan metode ini. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
